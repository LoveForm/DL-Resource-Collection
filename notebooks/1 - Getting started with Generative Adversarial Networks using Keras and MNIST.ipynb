{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GANs and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, Image\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as ktf\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def get_session(gpu_fraction=0.45):\n",
    "    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n",
    "\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "ktf.set_session(get_session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the discriminator\n",
    "\n",
    "In our two-player game the discriminator takes the role of the police: given an image it has to find out whether the image is fake or not. Given this requirement, the input of our discriminator network is a (28x28x1) input patch, equal to the dimensions of an MNIST image. The output is a single node. The setup of the networks is roughly based on the [DCGAN paper](https://arxiv.org/abs/1511.06434) and one of its [implementations](https://github.com/carpedm20/DCGAN-tensorflow).\n",
    "\n",
    "We use `LeakyReLU` in between the convolution layers to improve the gradients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    \n",
    "    net = Sequential()\n",
    "    input_shape = (28, 28, 1)\n",
    "    dropout_prob = 0.4\n",
    "\n",
    "    net.add(Conv2D(64, 5, strides=2, input_shape=input_shape, padding='same'))\n",
    "    net.add(LeakyReLU())\n",
    "    \n",
    "    net.add(Conv2D(128, 5, strides=2, padding='same'))\n",
    "    net.add(LeakyReLU())\n",
    "    net.add(Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(Conv2D(256, 5, strides=2, padding='same'))\n",
    "    net.add(LeakyReLU())\n",
    "    net.add(Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(Conv2D(512, 5, strides=1, padding='same'))\n",
    "    net.add(LeakyReLU())\n",
    "    net.add(Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(Flatten())\n",
    "    net.add(Dense(1))\n",
    "    net.add(Activation('sigmoid'))\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full network structure is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 8193      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,311,553\n",
      "Trainable params: 4,311,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net_discriminator = discriminator()\n",
    "net_discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the generator\n",
    "\n",
    "The task of the generator, also known as \"the counterfeiter\", is to fool the discriminator by producing real-looking fake images. These images should eventually resemble the data distribution of the MNIST dataset.\n",
    "\n",
    "The structure of the generator is comparable to the discrminiator but in reverse. We start with a random vector of noise (length=100) and gradually upsample. To improve the output of the generator we use `UpSampling2D` and normal convolutions instead of transposed convolutions (see also [this article](https://distill.pub/2016/deconv-checkerboard/)). The sizes of the layers are adjusted to match the size of our data (28x28 as opposed to the 64x64 of the DCGAN paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator():\n",
    "    \n",
    "    net = Sequential()\n",
    "    dropout_prob = 0.4\n",
    "    \n",
    "    net.add(Dense(7*7*256, input_dim=100))\n",
    "    net.add(BatchNormalization(momentum=0.9))\n",
    "    net.add(LeakyReLU())\n",
    "    net.add(Reshape((7,7,256)))\n",
    "    net.add(Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(UpSampling2D())\n",
    "    net.add(Conv2D(128, 5, padding='same'))\n",
    "    net.add(BatchNormalization(momentum=0.9))\n",
    "    net.add(LeakyReLU())\n",
    "    \n",
    "    net.add(UpSampling2D())\n",
    "    net.add(Conv2D(64, 5, padding='same'))\n",
    "    net.add(BatchNormalization(momentum=0.9))\n",
    "    net.add(LeakyReLU())\n",
    "    \n",
    "    net.add(Conv2D(32, 5, padding='same'))\n",
    "    net.add(BatchNormalization(momentum=0.9))\n",
    "    net.add(LeakyReLU())\n",
    "    \n",
    "    net.add(Conv2D(1, 5, padding='same'))\n",
    "    net.add(Activation('sigmoid'))\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full network of the generator looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 2,394,241\n",
      "Trainable params: 2,368,705\n",
      "Non-trainable params: 25,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net_generator = generator()\n",
    "net_generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the models\n",
    "\n",
    "We now defined the two separate networks but these still need to be combined in to two trainable models: one to train the discrmininator and one to train the generator. We first start with the most simple one which is the discriminator model.\n",
    "\n",
    "For the discriminator model we only have to define the optimizer, all the other parts of the model are already defined. We use `SGD` as the optimizer with a low learning rate and clip the values between -1 and 1. A small decay in the learning rate can help with stabilizing. Besides the loss we also tell Keras to gives us the accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 1)                 4311553   \n",
      "=================================================================\n",
      "Total params: 4,311,553\n",
      "Trainable params: 4,311,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optim_discriminator = RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-10)\n",
    "model_discriminator = Sequential()\n",
    "model_discriminator.add(net_discriminator)\n",
    "model_discriminator.compile(loss='binary_crossentropy', optimizer=optim_discriminator, metrics=['accuracy'])\n",
    "\n",
    "model_discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model for the generator is a bit more complex. The generator needs to fool the discriminator by generating images. To train the generator we need to assess its performance on the output of the discriminator. For this we add both networks to a combined model: *the adversarial model*. Our adverserial model uses random noise as its input and outputs the eventual prediction of the discriminator on the generated images. \n",
    "\n",
    "The generator performs well if the adverserial model outputs 'real' on all inputs. In other words, for any input of the adversial network aim to get an output classifying the generated image as real. This means, however, that the discriminator failed (which is a good thing for the generator). If we would use normal back propagation here on the full adversarial model we would update slowly push the discriminator to update itself and start classifying fake images as real. To prevent this we must freeze the part of the model that belongs to the discriminator.\n",
    "\n",
    "In Keras freezing a model is easily done by freezing all the layers of the model. By setting the `trainable` parameter to `False` we prevent the layer of updating within this particular model (it is still trainable in the discriminator model).\n",
    "\n",
    "The adversarial model uses `Adam` as the optimizer with the default values for the momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (None, 28, 28, 1)         2394241   \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 4311553   \n",
      "=================================================================\n",
      "Total params: 6,705,794\n",
      "Trainable params: 2,368,705\n",
      "Non-trainable params: 4,337,089\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optim_adversarial = Adam(lr=0.0004, clipvalue=1.0, decay=1e-10)\n